{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General ML Model Pipeline\n",
    "\n",
    "### Table of contents:\n",
    "1. Dependencies  \n",
    "2. Read-in data  \n",
    "3. Data cleanup  \n",
    "    3a. Check inconsistencies and determine data types  \n",
    "    3b. Fix inconsistencies  \n",
    "    3c. Re-code categorical data  \n",
    "    3d. Sequester dependent variable(s)   \n",
    "    3e. Missing data  \n",
    "4. Group imbalance  \n",
    "    4a. Check for group imbalances  \n",
    "    4b. Correct group imbalances by SMOTE or undersampling  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read-in data\n",
    "Read data and transform into dataframe.  \n",
    "Test case: local data in .csv format.\n",
    "Change read-in procedure depending on data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Check inconsistencies\n",
    "Custom function to check dataframe for inconsistencies in, e.g., data type and delimiters.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkInconsistencies(df: pd.DataFrame):\n",
    "\n",
    "    # Checking for missing values\n",
    "    print(\"Missing Values Check:\")\n",
    "    print(df.isna().sum())\n",
    "    \n",
    "    # Check for inconsistent data types\n",
    "    print(\"\\nData Types Check:\")\n",
    "    datatypes = df.dtypes\n",
    "    print(datatypes)\n",
    "    \n",
    "    # Check for numeric columns containing non-numeric data\n",
    "    print(\"\\nNon-numeric Data in Numeric Columns:\")\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        non_numeric = df[col].apply(lambda x: not pd.api.types.is_number(x))\n",
    "        if non_numeric.sum() > 0:\n",
    "            print(f\"Non-numeric values found in {col}:\")\n",
    "            print(df[non_numeric][col])\n",
    "    \n",
    "    # Checking for delimiter issues by finding any cell containing multiple delimiters\n",
    "    print(\"\\nDelimiter Issues Check (commas, semicolons):\")\n",
    "    delimiter_issues = df.applymap(lambda x: isinstance(x, str) and (',' in x or ';' in x))\n",
    "    if delimiter_issues.any().any():\n",
    "        print(\"Delimiter issues found in the following columns:\")\n",
    "        print(df.columns[delimiter_issues.any()])\n",
    "\n",
    "    # Checking for duplicate features\n",
    "    print(\"\\nDuplicate Columns Check:\")\n",
    "    duplicatecols = df[df.columns.duplicated()]\n",
    "    if not duplicatecols.empty:\n",
    "        print(f\"{len(duplicatecols)} duplicate columns found:\")\n",
    "        print(duplicatecols)\n",
    "    else:\n",
    "        print(\"No duplicate columns found.\")\n",
    "\n",
    "    # Checking for duplicate rows\n",
    "    print(\"\\nDuplicate Rows Check:\")\n",
    "    duplicaterows = df[df.duplicated()]\n",
    "    if not duplicaterows.empty:\n",
    "        print(f\"{len(duplicaterows)} duplicate rows found:\")\n",
    "        print(duplicaterows)\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")\n",
    "    \n",
    "    # Checking for inconsistent casing in string columns\n",
    "    print(\"\\nInconsistent Casing in String Columns:\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        inconsistent_case = df[col].apply(lambda x: isinstance(x, str) and (x != x.lower() and x != x.upper()))\n",
    "        if inconsistent_case.any():\n",
    "            print(f\"Inconsistent casing found in {col}:\")\n",
    "            print(df[inconsistent_case][col])\n",
    "\n",
    "    # Checking for extra whitespace in string columns\n",
    "    print(\"\\nExtra Whitespace in String Columns:\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        whitespace_issues = df[col].apply(lambda x: isinstance(x, str) and (x != x.strip()))\n",
    "        if whitespace_issues.any():\n",
    "            print(f\"Whitespace issues found in {col}:\")\n",
    "            print(df[whitespace_issues][col])\n",
    "\n",
    "    # Return inconsistency boolean and index vectors\n",
    "    return datatypes, duplicatecols, duplicaterows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Fix inconsistencies\n",
    "Custom function to fix inconsistencies in dataframe detected in step 3a.  \n",
    "Uses custom function that fills missing cells with unused markers to make working with the dataframe easier and prep for future flexibility in missing value handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillNaNmarker(df: pd.DataFrame, marker=999):\n",
    "\n",
    "    # check if marker is used anywhere in the dataset, fill NaNs with available recognizable marker\n",
    "    filled = False\n",
    "    while not filled:\n",
    "        if not marker in df:\n",
    "            df.fillna(marker, inplace=True)\n",
    "            filled = True\n",
    "        else:\n",
    "            marker = marker * 10 + 9\n",
    "\n",
    "    return marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixInconsistencies(df: pd.DataFrame, handleNaN = 'impute'):\n",
    "\n",
    "    # Converting non-numeric values in numeric columns to NaN and then filling or dropping\n",
    "    print(\"Fixing Non-numeric Data in Numeric Columns...\")\n",
    "    for col in df.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert non-numeric to NaN\n",
    "\n",
    "    # Handling missing values based on the handleNaN parameter\n",
    "    match handleNaN:\n",
    "        case 'impute':\n",
    "            # Note that imputation will happen later, here just fills NaNs in-place with known marker\n",
    "            marker = fillNaNmarker(df)\n",
    "            print(\"Filled NaNs with known value %d\" % marker)\n",
    "        case 'drop':\n",
    "            print(\"Dropping Rows with Missing Values...\")\n",
    "            df = df.dropna()  # Drop rows with missing values\n",
    "        case 'mean':\n",
    "            print(\"Filling Missing Values with column mean...\")\n",
    "            df = df.fillna(df.mean())  # Fill NaN values in numeric columns with column mean\n",
    "        case 'last':\n",
    "            print(\"Filling Missing Values with last known value...\")\n",
    "            df = df.fillna(method='ffill')  # Forward filling for missing values\n",
    "\n",
    "    # Fixing delimiter issues by replacing problematic delimiters (commas, semicolons)\n",
    "    print(\"Fixing Delimiter Issues...\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x).replace(',', '').replace(';', '') if isinstance(x, str) else x)\n",
    "\n",
    "    # Dropping duplicate rcolumns\n",
    "    print(\"Dropping Duplicate Columns...\")\n",
    "    df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "\n",
    "    # Standardizing casing in string columns (converting to lower case)\n",
    "    print(\"Fixing Inconsistent Casing in String Columns...\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x).lower() if isinstance(x, str) else x)\n",
    "\n",
    "    # Removing leading and trailing whitespaces from string columns\n",
    "    print(\"Fixing Extra Whitespace in String Columns...\")\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        df[col] = df[col].apply(lambda x: str(x).strip() if isinstance(x, str) else x)\n",
    "\n",
    "    print(\"All fixes applied.\")\n",
    "    return df, marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c. Re-code feature data\n",
    "Custom function to re-code categorical data using ordinal or one-hot encoding.  \n",
    "Uses custom function that determines ordinal or nominal data in dataframe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findOrdinalCols(df: pd.DataFrame, marker=None):\n",
    "\n",
    "    # Attempts to detect ordinality in categorical data to ensure proper later re-coding\n",
    "    print(\"Detecting Ordinality in Categorical Data...\")\n",
    "    ordinalCols = []\n",
    "    nominalCols = []\n",
    "    \n",
    "    # List of common ordinal keywords for heuristic detection\n",
    "    ordinal_keywords = ['low', 'medium', 'high', 'first', 'second', 'third', \n",
    "                        'poor', 'good', 'excellent', 'bad']\n",
    "    \n",
    "    for column_name in df.columns:\n",
    "        column = df[column_name]\n",
    "        \n",
    "        # If a marker is provided, filter out rows with the marker value\n",
    "        if marker is not None:\n",
    "            filtered_column = column[column != marker]\n",
    "        else:\n",
    "            filtered_column = column\n",
    "        \n",
    "        is_ordinal = False  # Flag to track if the column is detected as ordinal\n",
    "        \n",
    "        # Check if the column has an explicit ordered CategoricalDtype\n",
    "        if pd.api.types.is_categorical_dtype(filtered_column) and filtered_column.cat.ordered:\n",
    "            ordinalCols.append(column_name)\n",
    "            is_ordinal = True\n",
    "        elif pd.api.types.is_numeric_dtype(filtered_column):\n",
    "            # Detect numeric values that might represent an ordinal relationship\n",
    "            unique_values = sorted(filtered_column.dropna().unique())\n",
    "            if all(isinstance(x, (int, float)) for x in unique_values) and unique_values == sorted(unique_values):\n",
    "                ordinalCols.append(column_name)\n",
    "                is_ordinal = True\n",
    "        elif pd.api.types.is_object_dtype(filtered_column) or pd.api.types.is_categorical_dtype(filtered_column):\n",
    "            # Detect common ordinal words in categorical string data\n",
    "            unique_strings = filtered_column.dropna().astype(str).unique()\n",
    "            for value in unique_strings:\n",
    "                for keyword in ordinal_keywords:\n",
    "                    if re.search(keyword, value.lower()):\n",
    "                        ordinalCols.append(column_name)\n",
    "                        is_ordinal = True\n",
    "                        break\n",
    "        \n",
    "        # If not marked as ordinal, add to nominalCols\n",
    "        if not is_ordinal:\n",
    "            nominalCols.append(column_name)\n",
    "    \n",
    "    return ordinalCols, nominalCols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reCode(df: pd.DataFrame, marker=None):\n",
    "\n",
    "    # Re-code categorical data using ordinal or one-hot encoding. Note that the input dataframe is modified in-place, no return value is required.\n",
    "    print(\"One-hot Encoding Categorical Data...\")\n",
    "\n",
    "    # Find ordinal and nominal columns\n",
    "    ordinalCols, nominalCols = findOrdinalCols(df)\n",
    "    \n",
    "    # Re-code found columns using ordinal or one-hot encoding\n",
    "\n",
    "    # Ordinal Encoding: Convert ordinal columns to numeric values based on their order\n",
    "    for col in ordinalCols:\n",
    "        # Create a mask to track where the marker values are, if marker is provided\n",
    "        mask = df[col] == marker if marker is not None else None\n",
    "        \n",
    "        if pd.api.types.is_categorical_dtype(df[col]):\n",
    "            # If the column is categorical, map the categories to their ordinal values\n",
    "            df[col] = df[col].cat.codes\n",
    "        else:\n",
    "            # If it's not categorical but detected as ordinal, map the unique values to ordinal codes\n",
    "            unique_vals = sorted(df[col].dropna().unique())\n",
    "            ordinal_mapping = {val: idx for idx, val in enumerate(unique_vals)}\n",
    "            df[col] = df[col].map(ordinal_mapping)\n",
    "        \n",
    "        # Restore the marker values if they were masked\n",
    "        if marker is not None:\n",
    "            df.loc[mask, col] = marker\n",
    "\n",
    "    # One-Hot Encoding: Apply one-hot encoding to nominal columns\n",
    "    for col in nominalCols:\n",
    "        if marker is not None:\n",
    "            # Temporarily set marked values (marker) to NaN for one-hot encoding\n",
    "            mask = df[col] == marker\n",
    "            df.loc[mask, col] = None  # Replace marker with NaN\n",
    "    \n",
    "    # One-hot encode the nominal columns\n",
    "    df_nominal_encoded = pd.get_dummies(df[nominalCols], drop_first=False)\n",
    "    \n",
    "    # Drop the original nominal columns and concatenate the new one-hot encoded columns\n",
    "    df.drop(columns=nominalCols, inplace=True)\n",
    "    df[df_nominal_encoded.columns] = df_nominal_encoded\n",
    "\n",
    "    # Restore the marker values for nominal columns after one-hot encoding\n",
    "    for col in nominalCols:\n",
    "        if marker is not None:\n",
    "            df.loc[mask, col] = marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d. Sequester dependent variable(s)\n",
    "Custom function to split off dependent variables before further processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e. Impute missing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
